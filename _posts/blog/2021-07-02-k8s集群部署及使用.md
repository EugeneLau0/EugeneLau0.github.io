---
title: 'k8s集群部署及使用'
categories:
  - Blog
tags:
  - k8s
  - 运维
---

在学习k8s的过程中，通过实践的方式，将一些常用的命令总结下来。

<!--more-->

# 机器配置

主机配置：2G、2C、100G

master node：master1

worker node：worker1、worker2

## 查看IP:

```sh
ip addr
# 或者
ip a s
```

## 修改主机名：

```sh
hostnamectl set-hostname XXX
```

## 查看主机名：

```
hostname
```

## 设置IP：

```
vi /etc/sysconfig/network-scripts/ifcfg-ens33

BOOTPROT0="none"
IPADDR="172.16.177.100"
PREFIX="24"
GATEWAY="172.16.177.2"
DNS1="119.29.29.29"
```

## 重启网卡：

```
systemctl restart network
```

## 修改host文件(需要在root下)：

```
vi /etc/hosts

172.16.177.100 master1
172.16.177.101 worker1
172.16.177.102 worker2 
```

# 主机安全配置

## 关闭防火墙：

```sh
// 查看防护墙状态
systemctl status firewalld
// 停用防火墙
systemctl stop firewalld
// 开机禁用
systemctl disable firewalld
// 验证状态
firewall-cmd --state
```

## selinux修改：

```
// 查看
sestatus 或者 getenforce
// 修改
sed -ri 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config
// 重启生效
reboot
// 验证
getenforce
```

## 主机时间同步：

```
// 安装ntpdate
yum -y install ntpdate
// 设置同步规则
crontab -e
// 上一步内容
0 */1 * * * ntpdate time1.aliyun.com
// 主动同步
ntpdate time1.aliyun.com
```

## 关闭swap分区

使用kubeadm部署k8s，必须关闭swap分区，然后重启使配置生效

```
// 查看
cat /etc/fstab
// 注释swap行
vi /etc/fstab
// 重启
reboot
```

## 添加网桥过滤及地址转发

```
// 创建一个k8s配置文件 
vi /etc/sysctl.d/k8s.conf
// 上一步内容
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
vm.swappiness = 0
// 加载br_netfilter模块
modprobe br_netfilter
// 查看是否加载
lsmod | grep br_netfilter
// 加载网桥过滤配置文件
sysctl -p /etc/sysctl.d/k8s.conf
```

## 开启ipvs

```
 // 安装ipset及ipvsadm
 yum -y install ipset ipvsadm
 // 添加需要加载的模块，放到新建的文件ipvs.modules中
 cat > /etc/sysconfig/modules/ipvs.modules <<EOF #!/bin/bash
 modprobe -- ip_vs
 modprobe -- ip_vs_rr
 modprobe -- ip_vs_wrr
 modprobe -- ip_vs_sh
 modprobe -- nf_conntrack_ipv4
EOF
// 授权、运行、检查是否加载
chmod 755 /etc/sysconfig/modules/ipvs.modules
bash /etc/sysconfig/modules/ipvs.modules 
lsmod | grep -e ip_vs -e nf_conntrack_ipv4
```

# 安装docker-ce

## 在manager节点及worker节点安装指定版本的docker-ce

```
// yum源获取
wget -O /etc/yum.repos.d/docker-ce.repo https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo
// 查看yum源版本
yum list docker-ce.x86_64 --showduplicates | sort -r
// 安装指定版本，示例中的版本是比较稳定的
yum -y install --setopt=obsoletes=0 docker-ce-18.06.3.ce-3.el7
// 验证
docker version
// 设置docker开机自启
systemctl enable docker
// 启动docker
systemctl start docker
// 查看docker状态
systemctl status docker
```

## 修改docker-ce服务配置文件

```
// 修改docker的服务配置文件，当前版本不用修改，此步可以跳过。（包含ExecStart=XXX时需要修改)
cat /usr/lib/systemd/system/docker.service
// 增加配置文件
vi /etc/docker/daemon.json
// 文件内容，指定docker的驱动：原生的
{
    "exec-opts":["native.cgroupdriver=systemd"]
}
// 重启docker
systemctl restart docker
```

## 相关关联软件安装

包括：kubeadm、kubelet、kubectl、docker-ce（已安装）

```sh
// 创建存放文件：阿里云的k8s yum源
vi /etc/yum.repos.d/k8s.repo
// 文件内容
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg 
       https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
// 验证是否可用
yum list | grep kubeadm
// 复制当前yum源到其他两台机器的相同目录下
scp /etc/yum.repos.d/k8s.repo worker1:/etc/yum.repos.d/
// 安装指定版本
yum -y install --setopt=obsoletes=0 kubeadm-1.17.2-0 kubelet-1.17.2-0 kubectl-1.17.2-0
```

### 修改kubelet配置

```sh
// 保持docker的cgroupdriver和kubelet的cgroup一致性
vi /etc/sysconfig/kubelet
KUBELET_EXTRA_ARGS="--cgroup-driver=systemd"
// 开机自启
systemctl enable kubelet
```

# 集群镜像

##  master镜像

```sh
// 查看镜像
kubeadm config images list
// 将所有镜像保存到文件中，该方式是使用谷歌镜像，需要FQ
kubeadm config images list >> images.list
// 查看保存的文件
cat images.list
// 修改脚本（下载）
vi images.list
#!/bin/bash
img_list='k8s.gcr.io/kube-apiserver:v1.17.2
k8s.gcr.io/kube-controller-manager:v1.17.2
k8s.gcr.io/kube-scheduler:v1.17.2
k8s.gcr.io/kube-proxy:v1.17.2
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd:3.4.3-0
k8s.gcr.io/coredns:1.6.5'

for img in ${img_list}
do
        docker pull $img
done
// 执行脚本
sh images.list
// 改编后的脚本，可以从阿里云下载镜像
#!/bin/bash
img_list='kube-apiserver:v1.17.2
    kube-controller-manager:v1.17.2
    kube-scheduler:v1.17.2
    kube-proxy:v1.17.2
    pause:3.1
    etcd:3.4.3-0
    /coredns:1.6.5'

for img in ${img_list}
do
        docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$img
        docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$img k8s.gcr.io/$img
        docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$img
done
// 验证
docker images 
```

## worker镜像

```sh
// 从master节点上保存两个文件
docker save -o kube-p.tar k8s.gcr.io/kube-proxy:v1.17.2
docker save -o pause.tar k8s.gcr.io/pause:3.1
// 拷贝到两台worker机器的root下
scp kube-p.tar pause.tar worker1:/root/
// 在worker机器上导入
docker load -i kube-p.tar
docker load -i pause.tar
// 验证
docker images
```

## K8S集群初始化

```sh
// 在master上操作，该操作决定哪一台是master节点
kubeadm init --kubernetes-version=v1.17.2 --pod-network-cidr=172.16.0.0/16 --apiserver-advertise-address=172.16.177.100
// 按照第一步完成后的提示操作
mkdir .kube
cp -i /etc/kubernetes/admin.conf .kube/config
// calico资源：
// 从官网下载calico.yaml文件，并找到镜像的版本为v3.15.1
cat calico.yaml | grep image: | awk '{print $2}'
calico/cni:v3.15.1
calico/pod2daemon-flexvol:v3.15.1
calico/node:v3.15.1
calico/kube-controllers:v3.15.1
// 镜像下载
docker pull quay.io/calico/cni:v3.15.1
docker pull quay.io/calico/pod2daemon-flexvol:v3.15.1
docker pull quay.io/calico/node:v3.15.1
docker pull quay.io/calico/kube-controllers:v3.15.1
// 在当前目录导出镜像为压缩包
docker save -o calico-cni-v3.15.1.tar quay.io/calico/cni:v3.15.1
docker save -o calico-pod2daemon-flexvol-v3.15.1.tar quay.io/calico/pod2daemon-flexvol:v3.15.1
docker save -o calico-node-v3.15.1.tar quay.io/calico/node:v3.15.1
docker save -o calico-kube-controllers-v3.15.1.tar quay.io/calico/kube-controllers:v3.15.1
// 修改calico.ymal文件
// 执行使生效
kubectl apply -f calico.yaml
// 挂载
docker load -i XXX
// 执行一个自建的脚本，kubeadm join 生成token，同步到每个worker
sh gene_kube_token.sh 172.16.177.100
```

## 验证集群可用性

```sh
// 查看节点状态
kubectl get nodes
// 查看集群健康状态
kubectl get cs
或者
kubectl cluster-info
// 查看所有pods
kubectl get pods --namespace kube-system
```

# 使用集群

## kubectl管理工具的使用:

```
// 检查kubectl是否安装
rpm -qa | grep kubectl
// 获取kubectl帮助
kubectl --help
```

## 使用worker管理集群：

```
mkdir .kube
scp master1:/root/.kube/config .kube/
// 验证
kubectl get nodes
或
kubectl get pods -n kube-system
```

## namespace：命名空间

**namespace**：命名空间：多租户下，实现资源隔离；

```sh
// 查看命名空间
kubectl get namespace
或
kubectl get ns
// 创建命名空间：方式一
kubectl create namespace XXX
// 创建命名空间：方式二，通过资源清单文件创建
cat xxx.yaml .   // 准备资源文件
kubectl apply -f xxx.yaml // 应用资源文件
// 删除命名空间：方式一
kubectl delete namespace XXX
// 删除命名空间：方式二，通过资源清单文件删除
cat XXX.yaml // 准备资源清单文件
kubectl delete -f XXX.yaml  // 删除资源清单文件
```

## 拉取nginx镜像

```
// 拉取nginx镜像，只需要在worker节点中
docker pull registry.cn-shenzhen.aliyuncs.com/yansongda/nginx:latest
docker tag registry.cn-shenzhen.aliyuncs.com/yansongda/nginx nginx-latest
docker rmi registry.cn-shenzhen.aliyuncs.com/yansongda/nginx
```

## pod

pod：k8s能够调度的最小单元，是容器的封装

```
// 查看默认namespace的pod
kubectl get pod
或
kubectl get pods
// 查看指定namespace的pod
kubectl get pod --namespace kube-system
或
kubectl get pod -n kube-system

// 创建pod
vim 02-create-pod.yaml
apiVersion: v1
kind: Pod
metadata: 
  name: pod1
spec:
  containers:
  - name: nginx-container
    image: nginx-latest
    imagePullPolicy: Never
    ports:
    - name: nginxport
      containerPort: 80
// 应用资源清单
kubectl apply -f 02-create-pod.yaml
// 验证
kubectl get pods -n 
或
kubectl get pods -o wide // 显示更详细信息

// 删除pods，也可以通过删除资源清单
kubectl delete pods pod1 -n default
kubectl delete -f 02-create-pod.yaml
```

### 进入pod：

```
// podID：v7-scm-6db4b69f58-gbjzc，namespace：ns-retail-feature1
 kubectl exec -it v7-scm-6db4b69f58-gbjzc -n ns-retail-feature1  /bin/bash
```

## controller

**controller**：pod控制器，当pod不可用时重新拉起，提供高可用的实现

```
// 创建deployment控制器：用于部署、升级、副本...
// 创建一个nginx的应用
kubectl run nginx-app1 --image=nginx:latest --image-pull-policy=IfNotPresent --replicas=2
// 查看应用
kubectl get deployment.apps
// 查看创建
kubectl get replicaset
// 除了上面赭红方式也可以通过资源清单文件来做

// 删除控制器，不能直接删除pod，删除后会被立马拉起
kubectl delete deployment.apps nginx-app1
```

## service

**service**：用于对pod控制访问，即客户端访问pod入口

service是一条iptables或ipvs的转发规则，不是实体服务

```
// 1、创建应用
kubectl run nginx-app1 --image=nginx:latest --image-pull-policy=IfNotPresent --replicas=1
// 2、将service和应用关联
kubectl expose deployment.apps nginx-app1 --type=ClusterIp --target-port=80 --port=80
// 查看service
kubectl get service
// 删除service
kubectl delete service nginx-app1
```

